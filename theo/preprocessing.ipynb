{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import io, segmentation, color\n",
    "import networkx as nx\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filepath):\n",
    "    image_path = filepath\n",
    "    image = io.imread(image_path)\n",
    "\n",
    "    # If the image has 4 channels (RGBA), remove the alpha channel\n",
    "    if image.shape[-1] == 4: image = image[..., :3]\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images):\n",
    "    n = len(images)\n",
    "\n",
    "    fig, axes = plt.subplots(1, n, figsize=(5 * n, 5))\n",
    "    if n == 1: axes = [axes]\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        if len(images[i].shape) == 3: ax.imshow(images[i])\n",
    "        else: ax.imshow(images[i], cmap='gray')\n",
    "        \n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/theo/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2024-10-11 Python-3.12.6 torch-2.4.1+cu121 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load YOLOv5 model (keeping it as an option for detection)\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "def isolate_objects(image):\n",
    "    \"\"\"\n",
    "    Isolate objects in an image by detecting them using YOLO and removing the background using\n",
    "    color thresholding and contour-based segmentation.\n",
    "    \n",
    "    Args:\n",
    "    - image: np.array, input image (RGB).\n",
    "    \n",
    "    Returns:\n",
    "    - isolated_image: np.array, image with objects isolated and background removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the image to the HSV color space for better color segmentation\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define color thresholds (adjust these based on actual colors)\n",
    "    lower_color = np.array([0, 50, 50])\n",
    "    upper_color = np.array([180, 255, 255])\n",
    "\n",
    "    # Create a binary mask where the detected colors are in the range and the background is black\n",
    "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    \n",
    "    # Apply morphological operations to clean up the mask\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Find contours based on the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create a blank mask to draw the contours\n",
    "    object_mask = np.zeros_like(mask)\n",
    "\n",
    "    # Draw filled contours for each detected object on the mask\n",
    "    cv2.drawContours(object_mask, contours, -1, 255, thickness=cv2.FILLED)\n",
    "    \n",
    "    # Create a 3-channel mask from the single-channel mask\n",
    "    object_mask_3channel = cv2.merge([object_mask, object_mask, object_mask])\n",
    "    \n",
    "    # Apply the mask to the image to remove the background\n",
    "    isolated_image = cv2.bitwise_and(image, object_mask_3channel)\n",
    "\n",
    "    # Check the isolated image\n",
    "    cv2.imshow('Isolated Image', isolated_image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    return isolated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "# Load the image (replace 'path_to_image.jpg' with your actual image path)\n",
    "image = cv2.imread('../COMP90086_2024_Project_train/train/173.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "\n",
    "# Isolate objects and remove the background\n",
    "isolated_image = isolate_objects(image)\n",
    "\n",
    "show_images([isolated_image])\n",
    "\n",
    "for i in isolated_image: print(i)\n",
    "\n",
    "# Display the original and isolated images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Isolated Objects with Black Background')\n",
    "plt.imshow(isolated_image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 68  52  35]\n",
      "  [ 68  52  35]\n",
      "  [ 68  52  35]\n",
      "  ...\n",
      "  [ 68  52  35]\n",
      "  [ 68  52  35]\n",
      "  [ 68  52  35]]\n",
      "\n",
      " [[ 68  52  35]\n",
      "  [ 68  52  35]\n",
      "  [ 68  52  35]\n",
      "  ...\n",
      "  [ 68  52  35]\n",
      "  [ 68  52  35]\n",
      "  [ 68  52  35]]\n",
      "\n",
      " [[ 68  52  35]\n",
      "  [ 68  52  35]\n",
      "  [ 68  52  35]\n",
      "  ...\n",
      "  [ 68  52  35]\n",
      "  [ 68  52  35]\n",
      "  [ 68  52  35]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[176 186 216]\n",
      "  [ 99 110 140]\n",
      "  [ 67  78 108]\n",
      "  ...\n",
      "  [ 86 101 127]\n",
      "  [ 61  75 103]\n",
      "  [142 156 184]]\n",
      "\n",
      " [[198 209 241]\n",
      "  [142 155 187]\n",
      "  [134 147 179]\n",
      "  ...\n",
      "  [103 119 142]\n",
      "  [136 151 177]\n",
      "  [152 169 195]]\n",
      "\n",
      " [[185 198 230]\n",
      "  [164 177 209]\n",
      "  [160 175 208]\n",
      "  ...\n",
      "  [ 64  80 103]\n",
      "  [ 74  91 117]\n",
      "  [108 125 151]]]\n"
     ]
    }
   ],
   "source": [
    "img = load_image('../COMP90086_2024_Project_train/train/173.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "isolated_img = isolate_objects(img)\n",
    "print(isolated_img)\n",
    "show_images([isolated_img])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
